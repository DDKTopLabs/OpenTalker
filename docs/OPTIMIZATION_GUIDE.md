# OpenTalker æ€§èƒ½ä¼˜åŒ–æŒ‡å—

æœ¬æ–‡æ¡£ä»‹ç»å¦‚ä½•åœ¨ 4GB æ˜¾å­˜çš„ GPUï¼ˆå¦‚ GTX 1050 Tiï¼‰ä¸Šä¼˜åŒ– OpenTalker çš„æ€§èƒ½å’Œæ˜¾å­˜å ç”¨ã€‚

## ğŸ“Š ä¼˜åŒ–æ¦‚è§ˆ

| ä¼˜åŒ–é¡¹ | æ˜¾å­˜èŠ‚çœ | æ€§èƒ½å½±å“ | æ¨èåœºæ™¯ |
|--------|---------|---------|---------|
| **FP16 åŠç²¾åº¦æ¨ç†** | ~50% | è½»å¾®åŠ é€Ÿ | æ‰€æœ‰ CUDA GPU |
| **æ–‡æœ¬åˆ†å—åˆæˆ** | ç¨³å®šæ˜¾å­˜ | æ— å½±å“ | é•¿æ–‡æœ¬ TTS |
| **ä¼˜åŒ–é•œåƒ** | ç£ç›˜èŠ‚çœ 38% | æ— å½±å“ | æ‰€æœ‰åœºæ™¯ |
| **å•æœåŠ¡éƒ¨ç½²** | èŠ‚çœ 2-3GB | åŠŸèƒ½å—é™ | 4GB æ˜¾å­˜ |

---

## ğŸš€ 1. FP16 åŠç²¾åº¦æ¨ç†

### åŸç†

FP16ï¼ˆåŠç²¾åº¦æµ®ç‚¹ï¼‰ä½¿ç”¨ 16 ä½è€Œä¸æ˜¯ 32 ä½æ¥å­˜å‚¨æ¨¡å‹å‚æ•°ï¼Œå¯ä»¥ï¼š
- **æ˜¾å­˜å ç”¨å‡åŠ**ï¼ˆçº¦ 50%ï¼‰
- **æ¨ç†é€Ÿåº¦æå‡**ï¼ˆPascal æ¶æ„åŠä»¥ä¸Šï¼‰
- **ç²¾åº¦æŸå¤±æå°**ï¼ˆè¯­éŸ³ä»»åŠ¡å‡ ä¹æ— å½±å“ï¼‰

### STT æœåŠ¡å¯ç”¨ FP16

**ç¯å¢ƒå˜é‡é…ç½®**ï¼š
```yaml
environment:
  - QWEN_ASR_USE_FP16=true  # å¯ç”¨ FP16ï¼ˆé»˜è®¤ï¼štrueï¼‰
```

**æ˜¾å­˜å¯¹æ¯”**ï¼š
| æ¨¡å¼ | æ˜¾å­˜å ç”¨ | è¯´æ˜ |
|------|---------|------|
| FP32 | ~3.1GB | é»˜è®¤å…¨ç²¾åº¦ |
| FP16 | ~1.6GB | åŠç²¾åº¦ï¼ˆæ¨èï¼‰ |

**ç¤ºä¾‹é…ç½®**ï¼š
```yaml
services:
  stt:
    image: ghcr.io/ddktoplabs/opentalker-stt:v0.3.0-optimized
    environment:
      - MODEL_NAME=Qwen/Qwen3-ASR-0.6B
      - DEVICE=cuda
      - QWEN_ASR_USE_FP16=true  # å¯ç”¨ FP16
```

### TTS æœåŠ¡ç²¾åº¦

TTS æœåŠ¡é»˜è®¤ä½¿ç”¨ **bfloat16**ï¼ˆBrain Float 16ï¼‰ï¼Œå·²ç»æ˜¯ä¼˜åŒ–çš„åŠç²¾åº¦æ ¼å¼ï¼š
- æ˜¾å­˜å ç”¨ï¼š~2.0GB
- æ— éœ€é¢å¤–é…ç½®
- ç²¾åº¦å’Œ FP32 æ¥è¿‘

---

## ğŸ“ 2. æ–‡æœ¬åˆ†å—åˆæˆ

### åŸç†

é•¿æ–‡æœ¬ï¼ˆå¦‚æ•´ç« å°è¯´ï¼‰ä¼šå¯¼è‡´ï¼š
- **æ˜¾å­˜éšæ–‡æœ¬é•¿åº¦å¢åŠ **
- **å¯èƒ½è§¦å‘ OOM é”™è¯¯**
- **åˆæˆæ—¶é—´è¿‡é•¿**

åˆ†å—åˆæˆå¯ä»¥ï¼š
- **ç¨³å®šæ˜¾å­˜å ç”¨**
- **é¿å… OOM**
- **æ”¯æŒè¶…é•¿æ–‡æœ¬**

### å¯ç”¨æ–‡æœ¬åˆ†å—

**ç¯å¢ƒå˜é‡é…ç½®**ï¼š
```yaml
environment:
  - QWEN_TTS_CHUNK_SIZE=200  # æ¯å—æœ€å¤§å­—ç¬¦æ•°ï¼ˆ0=ç¦ç”¨ï¼‰
```

**æ¨èé…ç½®**ï¼š
| æ–‡æœ¬é•¿åº¦ | æ¨è chunk_size | è¯´æ˜ |
|---------|----------------|------|
| < 100 å­—ç¬¦ | 0ï¼ˆç¦ç”¨ï¼‰ | çŸ­æ–‡æœ¬æ— éœ€åˆ†å— |
| 100-500 å­—ç¬¦ | 200 | ä¸­ç­‰æ–‡æœ¬ |
| > 500 å­—ç¬¦ | 150-200 | é•¿æ–‡æœ¬ï¼ˆå°è¯´ã€æ–‡ç« ï¼‰ |

**ç¤ºä¾‹é…ç½®**ï¼š
```yaml
services:
  tts:
    image: ghcr.io/ddktoplabs/opentalker-tts:v0.3.0-optimized
    environment:
      - MODEL_NAME=Qwen/Qwen3-TTS-12Hz-0.6B-CustomVoice
      - DEVICE=cuda
      - QWEN_TTS_CHUNK_SIZE=200  # å¯ç”¨åˆ†å—
```

### åˆ†å—é€»è¾‘

æ–‡æœ¬ä¼šåœ¨ä»¥ä¸‹æ ‡ç‚¹ç¬¦å·å¤„åˆ†å‰²ï¼š
- ä¸­æ–‡ï¼š`ã€‚ï¼ï¼Ÿï¼›`
- è‹±æ–‡ï¼š`.!?;`

åˆ†å—åçš„éŸ³é¢‘ä¼šè‡ªåŠ¨æ‹¼æ¥ï¼Œç”¨æˆ·æ— æ„ŸçŸ¥ã€‚

---

## ğŸ¯ 3. 4GB æ˜¾å­˜ä¼˜åŒ–æ–¹æ¡ˆ

### æ–¹æ¡ˆ Aï¼šSTT + TTS åŒæ—¶è¿è¡Œï¼ˆéœ€è¦ä¼˜åŒ–ï¼‰

**é…ç½®**ï¼š
```yaml
services:
  stt:
    environment:
      - QWEN_ASR_USE_FP16=true  # å¯ç”¨ FP16
  tts:
    environment:
      - QWEN_TTS_CHUNK_SIZE=200  # å¯ç”¨åˆ†å—
```

**æ˜¾å­˜å ç”¨**ï¼š
- STT (FP16): ~1.6GB
- TTS (bfloat16): ~2.0GB
- **æ€»è®¡**: ~3.6GB âœ… å¯ç”¨

### æ–¹æ¡ˆ Bï¼šå•æœåŠ¡éƒ¨ç½²ï¼ˆæœ€ç¨³å®šï¼‰

**ä»… STT**ï¼š
```bash
docker compose -f examples/docker/docker-compose.stt-only.yml up -d
```

**ä»… TTS**ï¼š
```bash
docker compose -f examples/docker/docker-compose.tts-only.yml up -d
```

**æ˜¾å­˜å ç”¨**ï¼š
- å• STT: ~1.6GB (FP16)
- å• TTS: ~2.0GB (bfloat16)

---

## ğŸ”„ 4. å®æ—¶è¯­éŸ³å¯¹è®²æ–¹æ¡ˆ

### ä½¿ç”¨ Faster-Whisper æ›¿ä»£ Qwen3-ASR

**ä¼˜åŠ¿**ï¼š
- **æ›´ä½æ˜¾å­˜**ï¼šSmall æ¨¡å‹ ~1.2GBï¼ŒMedium-int8 ~1.5GB
- **æ›´å¿«é€Ÿåº¦**ï¼šä¼˜åŒ–çš„ CTranslate2 å¼•æ“
- **æ›´å¥½å…¼å®¹**ï¼šä¸ IndexTTS å®Œç¾é…åˆ

**æ˜¾å­˜åˆ†é…**ï¼š
```
STT (Faster-Whisper Small): ~1.2GB
TTS (IndexTTS bfloat16):    ~2.0GB
ç³»ç»Ÿç¼“å†²:                    ~0.8GB
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
æ€»è®¡:                        4.0GB âœ…
```

### å®ç°æ–¹æ¡ˆ

1. **æ›¿æ¢ STT æœåŠ¡**ä¸º Faster-Whisper
2. **ä¿æŒ TTS æœåŠ¡**ä¸å˜
3. **å¯ç”¨æµå¼å¤„ç†**å‡å°‘å»¶è¿Ÿ

**å‚è€ƒé¡¹ç›®**ï¼š
- [faster-whisper](https://github.com/guillaumekln/faster-whisper)
- [whisper.cpp](https://github.com/ggerganov/whisper.cpp)

---

## ğŸ“ˆ 5. æ€§èƒ½å¯¹æ¯”

### STT æ€§èƒ½å¯¹æ¯”

| é…ç½® | æ˜¾å­˜ | é€Ÿåº¦ | ç²¾åº¦ |
|------|------|------|------|
| Qwen3-ASR FP32 | 3.1GB | 1.0x | 100% |
| Qwen3-ASR FP16 | 1.6GB | 1.2x | 99.5% |
| Faster-Whisper Small | 1.2GB | 2.0x | 95% |
| Faster-Whisper Medium-int8 | 1.5GB | 1.5x | 98% |

### TTS æ€§èƒ½å¯¹æ¯”

| é…ç½® | æ˜¾å­˜ | é€Ÿåº¦ | è´¨é‡ |
|------|------|------|------|
| IndexTTS FP32 | 3.8GB | 1.0x | 100% |
| IndexTTS bfloat16 | 2.0GB | 1.0x | 99.8% |
| IndexTTS FP16 | 1.9GB | 1.1x | 99.5% |

---

## ğŸ› ï¸ 6. å®Œæ•´é…ç½®ç¤ºä¾‹

### 4GB æ˜¾å­˜ä¼˜åŒ–é…ç½®

```yaml
version: '3.8'

services:
  stt:
    image: ghcr.io/ddktoplabs/opentalker-stt:v0.3.0-optimized
    container_name: opentalker-stt
    ports:
      - "8001:8001"
    environment:
      - MODEL_NAME=Qwen/Qwen3-ASR-0.6B
      - DEVICE=cuda
      - LOG_LEVEL=INFO
      - HF_ENDPOINT=https://hf-mirror.com
      # ä¼˜åŒ–é…ç½®
      - QWEN_ASR_USE_FP16=true           # å¯ç”¨ FP16ï¼Œæ˜¾å­˜å‡åŠ
      - QWEN_ASR_MAX_BATCH_SIZE=4        # å‡å°æ‰¹å¤„ç†å¤§å°
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]

  tts:
    image: ghcr.io/ddktoplabs/opentalker-tts:v0.3.0-optimized
    container_name: opentalker-tts
    ports:
      - "8002:8002"
    environment:
      - MODEL_NAME=Qwen/Qwen3-TTS-12Hz-0.6B-CustomVoice
      - DEVICE=cuda
      - LOG_LEVEL=INFO
      - HF_ENDPOINT=https://hf-mirror.com
      # ä¼˜åŒ–é…ç½®
      - QWEN_TTS_CHUNK_SIZE=200          # å¯ç”¨æ–‡æœ¬åˆ†å—
      - QWEN_TTS_SPEAKER=female_calm     # é»˜è®¤è¯´è¯äºº
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
```

### 8GB+ æ˜¾å­˜æ ‡å‡†é…ç½®

```yaml
# 8GB ä»¥ä¸Šæ˜¾å­˜æ— éœ€ç‰¹æ®Šä¼˜åŒ–
services:
  stt:
    environment:
      - QWEN_ASR_USE_FP16=false  # å¯é€‰ï¼šä½¿ç”¨ FP32 è·å¾—æœ€é«˜ç²¾åº¦
      
  tts:
    environment:
      - QWEN_TTS_CHUNK_SIZE=0    # ç¦ç”¨åˆ†å—ï¼Œæ€§èƒ½æœ€ä½³
```

---

## ğŸ§ª 7. æµ‹è¯•å’ŒéªŒè¯

### æ£€æŸ¥æ˜¾å­˜å ç”¨

```bash
# æŸ¥çœ‹ GPU æ˜¾å­˜ä½¿ç”¨
nvidia-smi

# æŸ¥çœ‹å…·ä½“è¿›ç¨‹æ˜¾å­˜
nvidia-smi --query-compute-apps=pid,used_memory --format=csv
```

### æµ‹è¯• FP16 æ•ˆæœ

```bash
# å¯ç”¨ FP16
curl -X POST http://localhost:8001/v1/audio/transcriptions \
  -F "file=@test.wav" \
  -F "model=whisper-1"

# å¯¹æ¯”æ˜¾å­˜å ç”¨
nvidia-smi
```

### æµ‹è¯•æ–‡æœ¬åˆ†å—

```bash
# å‘é€é•¿æ–‡æœ¬
curl -X POST http://localhost:8002/v1/audio/speech \
  -H "Content-Type: application/json" \
  -d '{
    "model": "tts-1",
    "input": "è¿™æ˜¯ä¸€æ®µå¾ˆé•¿çš„æ–‡æœ¬..." (500+ å­—ç¬¦),
    "voice": "alloy"
  }' \
  --output long_text.wav

# æ£€æŸ¥æ—¥å¿—
docker logs opentalker-tts | grep "chunk"
```

---

## ğŸ“š 8. å¸¸è§é—®é¢˜

### Q: FP16 ä¼šå½±å“è¯†åˆ«/åˆæˆè´¨é‡å—ï¼Ÿ

**A**: å½±å“æå°ï¼ˆ<0.5%ï¼‰ï¼Œäººè€³å‡ ä¹æ— æ³•å¯Ÿè§‰ã€‚è¯­éŸ³ä»»åŠ¡å¯¹ç²¾åº¦è¦æ±‚ä¸å¦‚å›¾åƒä»»åŠ¡é«˜ã€‚

### Q: æ–‡æœ¬åˆ†å—ä¼šæœ‰åœé¡¿æ„Ÿå—ï¼Ÿ

**A**: ä¸ä¼šã€‚åˆ†å—åœ¨å¥å­è¾¹ç•Œè¿›è¡Œï¼ŒéŸ³é¢‘æ— ç¼æ‹¼æ¥ï¼Œå¬æ„Ÿè‡ªç„¶ã€‚

### Q: 4GB æ˜¾å­˜èƒ½åŒæ—¶è¿è¡Œ STT å’Œ TTS å—ï¼Ÿ

**A**: 
- **å¯ç”¨ FP16**: å¯ä»¥ï¼ˆ~3.6GBï¼‰âœ…
- **ä¸å¯ç”¨ FP16**: ä¸è¡Œï¼ˆ~5.1GBï¼‰âŒ

### Q: å¦‚ä½•é€‰æ‹© chunk_sizeï¼Ÿ

**A**: 
- çŸ­æ–‡æœ¬ï¼ˆ<100 å­—ï¼‰ï¼š0ï¼ˆç¦ç”¨ï¼‰
- ä¸­ç­‰æ–‡æœ¬ï¼ˆ100-500 å­—ï¼‰ï¼š200
- é•¿æ–‡æœ¬ï¼ˆ>500 å­—ï¼‰ï¼š150-200

### Q: Faster-Whisper æ¯” Qwen3-ASR å¥½å—ï¼Ÿ

**A**: å„æœ‰ä¼˜åŠ¿ï¼š
- **Faster-Whisper**: æ›´å¿«ã€æ›´çœæ˜¾å­˜ã€æ›´æˆç†Ÿ
- **Qwen3-ASR**: ä¸­æ–‡æ•ˆæœæ›´å¥½ã€æ›´æ–°çš„æ¨¡å‹

---

## ğŸ¯ 9. æ¨èé…ç½®æ€»ç»“

### GTX 1050 Ti (4GB)

```yaml
# æ¨èé…ç½®
STT:
  - QWEN_ASR_USE_FP16=true
  - QWEN_ASR_MAX_BATCH_SIZE=4

TTS:
  - QWEN_TTS_CHUNK_SIZE=200
```

**é¢„æœŸæ˜¾å­˜**: ~3.6GB

### RTX 2060 (6GB)

```yaml
# æ ‡å‡†é…ç½®
STT:
  - QWEN_ASR_USE_FP16=true  # å¯é€‰

TTS:
  - QWEN_TTS_CHUNK_SIZE=0   # ç¦ç”¨åˆ†å—
```

**é¢„æœŸæ˜¾å­˜**: ~5.1GB (FP32) æˆ– ~3.6GB (FP16)

### RTX 3090 (24GB)

```yaml
# é«˜æ€§èƒ½é…ç½®
STT:
  - QWEN_ASR_USE_FP16=false  # ä½¿ç”¨ FP32
  - QWEN_ASR_MAX_BATCH_SIZE=16

TTS:
  - QWEN_TTS_CHUNK_SIZE=0    # ç¦ç”¨åˆ†å—
```

**é¢„æœŸæ˜¾å­˜**: ~5.1GBï¼ˆå¤§é‡ä½™é‡ï¼‰

---

## ğŸ“– ç›¸å…³æ–‡æ¡£

- [Docker éƒ¨ç½²æŒ‡å—](DOCKER_GUIDE.md)
- [4GB æ˜¾å­˜éƒ¨ç½²æ–¹æ¡ˆ](DOCKER_GUIDE.md#-4gb-æ˜¾å­˜éƒ¨ç½²æ–¹æ¡ˆ)
- [Dockerfile ä¼˜åŒ–å¯¹æ¯”](DOCKERFILE_OPTIMIZATION_COMPARISON.md)
- [é¡¹ç›®ç»“æ„](../PROJECT_STRUCTURE.md)

---

**æœ€åæ›´æ–°**: 2026-02-05  
**ç‰ˆæœ¬**: v0.3.0
