# OpenTalker Docker é•œåƒä½¿ç”¨æŒ‡å—

## ğŸ“¦ é•œåƒä»“åº“

æ‰€æœ‰é•œåƒå·²å‘å¸ƒåˆ° GitHub Container Registry (GHCR)ï¼Œ**å®Œå…¨å…¬å¼€**ï¼Œæ— éœ€è®¤è¯å³å¯æ‹‰å–ã€‚

### é•œåƒåˆ—è¡¨

| æœåŠ¡ | é•œåƒåœ°å€ | å¤§å° | è¯´æ˜ |
|------|---------|------|------|
| Gateway | `ghcr.io/ddktoplabs/opentalker-gateway:v0.3.0` | 82.5MB | API ç½‘å…³æœåŠ¡ |
| STT Service | `ghcr.io/ddktoplabs/opentalker-stt:v0.3.0` | 5.55GB | è¯­éŸ³è¯†åˆ«æœåŠ¡ (Qwen3-ASR) |
| TTS Service | `ghcr.io/ddktoplabs/opentalker-tts:v0.3.0` | 5.49GB | è¯­éŸ³åˆæˆæœåŠ¡ (Qwen3-TTS) |

### é•œåƒæ ‡ç­¾

- `latest` - æœ€æ–°ç‰ˆæœ¬
- `v0.3.0` - ç¨³å®šç‰ˆæœ¬ï¼ˆæ¨èï¼‰

---

## ğŸš€ å¿«é€Ÿå¼€å§‹

### æ–¹æ³• 1ï¼šä½¿ç”¨å®˜æ–¹ GHCRï¼ˆå›½é™…ï¼‰

```bash
# æ‹‰å–é•œåƒ
docker pull ghcr.io/ddktoplabs/opentalker-gateway:v0.3.0
docker pull ghcr.io/ddktoplabs/opentalker-stt:v0.3.0
docker pull ghcr.io/ddktoplabs/opentalker-tts:v0.3.0

# ä½¿ç”¨ Docker Compose å¯åŠ¨
docker-compose -f docker-compose.ghcr.yml up -d
```

### æ–¹æ³• 2ï¼šä½¿ç”¨å›½å†…é•œåƒæºï¼ˆæ¨èï¼‰ğŸ‡¨ğŸ‡³

**å›½å†…ç”¨æˆ·å¯ä»¥ä½¿ç”¨ `ghcr.1ms.run` é•œåƒæºåŠ é€Ÿä¸‹è½½ï¼š**

```bash
# æ‹‰å–é•œåƒï¼ˆä½¿ç”¨å›½å†…é•œåƒæºï¼‰
docker pull ghcr.1ms.run/ddktoplabs/opentalker-gateway:v0.3.0
docker pull ghcr.1ms.run/ddktoplabs/opentalker-stt:v0.3.0
docker pull ghcr.1ms.run/ddktoplabs/opentalker-tts:v0.3.0

# é‡æ–°æ ‡è®°ä¸ºæ ‡å‡†åç§°ï¼ˆå¯é€‰ï¼‰
docker tag ghcr.1ms.run/ddktoplabs/opentalker-gateway:v0.3.0 ghcr.io/ddktoplabs/opentalker-gateway:v0.3.0
docker tag ghcr.1ms.run/ddktoplabs/opentalker-stt:v0.3.0 ghcr.io/ddktoplabs/opentalker-stt:v0.3.0
docker tag ghcr.1ms.run/ddktoplabs/opentalker-tts:v0.3.0 ghcr.io/ddktoplabs/opentalker-tts:v0.3.0
```

### æ–¹æ³• 3ï¼šä½¿ç”¨å›½å†…é•œåƒæºçš„ Docker Compose

åˆ›å»º `docker-compose.china.yml`ï¼š

```yaml
version: '3.8'

services:
  gateway:
    image: ghcr.1ms.run/ddktoplabs/opentalker-gateway:v0.3.0
    container_name: opentalker-gateway
    ports:
      - "8000:8000"
    environment:
      - GATEWAY_HOST=0.0.0.0
      - GATEWAY_PORT=8000
      - LOG_LEVEL=INFO
      - STT_SERVICE_URL=http://stt-service:8001
      - TTS_SERVICE_URL=http://tts-service:8002
      - STT_TIMEOUT=120
      - TTS_TIMEOUT=180
    depends_on:
      - stt-service
      - tts-service
    networks:
      - opentalker-network
    restart: unless-stopped

  stt-service:
    image: ghcr.1ms.run/ddktoplabs/opentalker-stt:v0.3.0
    container_name: opentalker-stt
    ports:
      - "8001:8001"
    environment:
      - SERVICE_HOST=0.0.0.0
      - SERVICE_PORT=8001
      - LOG_LEVEL=INFO
      - QWEN_ASR_MODEL=Qwen/Qwen3-ASR-0.6B
      - QWEN_ASR_DEVICE=cuda:0
      - QWEN_ASR_MAX_BATCH_SIZE=8
      - MAX_UPLOAD_SIZE=52428800
      - HF_ENDPOINT=https://hf-mirror.com
    volumes:
      - ./models:/models
      - ./stt-service/tmp:/app/tmp
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
    networks:
      - opentalker-network
    restart: unless-stopped

  tts-service:
    image: ghcr.1ms.run/ddktoplabs/opentalker-tts:v0.3.0
    container_name: opentalker-tts
    ports:
      - "8002:8002"
    environment:
      - SERVICE_HOST=0.0.0.0
      - SERVICE_PORT=8002
      - LOG_LEVEL=INFO
      - QWEN_TTS_MODEL=Qwen/Qwen3-TTS-12Hz-0.6B-CustomVoice
      - QWEN_TTS_DEVICE=cuda:0
      - HF_ENDPOINT=https://hf-mirror.com
    volumes:
      - ./models:/models
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
    networks:
      - opentalker-network
    restart: unless-stopped

networks:
  opentalker-network:
    driver: bridge
```

å¯åŠ¨æœåŠ¡ï¼š

```bash
docker-compose -f docker-compose.china.yml up -d
```

---

## ğŸŒ é•œåƒæºå¯¹æ¯”

| é•œåƒæº | åœ°å€ | é€‚ç”¨åœ°åŒº | é€Ÿåº¦ |
|--------|------|---------|------|
| **å®˜æ–¹ GHCR** | `ghcr.io` | å›½é™… | å›½å¤–å¿«ï¼Œå›½å†…æ…¢ |
| **å›½å†…é•œåƒ** | `ghcr.1ms.run` | ä¸­å›½å¤§é™† | å›½å†…å¿« âš¡ |

### å…¶ä»–å¯ç”¨çš„å›½å†…é•œåƒæº

```bash
# 1ms.run é•œåƒæºï¼ˆæ¨èï¼‰
ghcr.1ms.run/ddktoplabs/opentalker-gateway:v0.3.0

# å…¶ä»–é•œåƒæºï¼ˆå¦‚æœ 1ms.run ä¸å¯ç”¨ï¼‰
# æ³¨æ„ï¼šä»¥ä¸‹é•œåƒæºå¯èƒ½éœ€è¦è‡ªè¡ŒéªŒè¯å¯ç”¨æ€§
ghcr.dockerproxy.com/ddktoplabs/opentalker-gateway:v0.3.0
```

---

## ğŸ“ ä½¿ç”¨è¯´æ˜

### 1. å‡†å¤‡ç¯å¢ƒ

**ç³»ç»Ÿè¦æ±‚**ï¼š
- Ubuntu 22.04 æˆ–æ›´é«˜ç‰ˆæœ¬
- Docker 20.10+ 
- Docker Compose v2.0+
- NVIDIA GPUï¼ˆæ”¯æŒ CUDA 12.1ï¼‰
- NVIDIA Container Toolkit

**å®‰è£… NVIDIA Container Toolkit**ï¼š

```bash
# æ·»åŠ  NVIDIA ä»“åº“
distribution=$(. /etc/os-release;echo $ID$VERSION_ID)
curl -s -L https://nvidia.github.io/nvidia-docker/gpgkey | sudo apt-key add -
curl -s -L https://nvidia.github.io/nvidia-docker/$distribution/nvidia-docker.list | \
  sudo tee /etc/apt/sources.list.d/nvidia-docker.list

# å®‰è£…
sudo apt-get update
sudo apt-get install -y nvidia-container-toolkit

# é‡å¯ Docker
sudo systemctl restart docker
```

### 2. åˆ›å»ºé¡¹ç›®ç›®å½•

```bash
mkdir -p ~/opentalker
cd ~/opentalker
mkdir -p models stt-service/tmp
```

### 3. ä¸‹è½½ Docker Compose é…ç½®

```bash
# å›½é™…ç”¨æˆ·
wget https://raw.githubusercontent.com/DDKTopLabs/OpenTalker/main/docker-compose.ghcr.yml

# å›½å†…ç”¨æˆ·ï¼ˆä½¿ç”¨é•œåƒæºï¼‰
wget https://raw.githubusercontent.com/DDKTopLabs/OpenTalker/main/docker-compose.china.yml
```

### 4. å¯åŠ¨æœåŠ¡

```bash
# å›½é™…ç”¨æˆ·
docker-compose -f docker-compose.ghcr.yml up -d

# å›½å†…ç”¨æˆ·
docker-compose -f docker-compose.china.yml up -d

# æŸ¥çœ‹æ—¥å¿—
docker-compose logs -f

# æŸ¥çœ‹æœåŠ¡çŠ¶æ€
docker-compose ps
```

### 5. éªŒè¯æœåŠ¡

```bash
# æ£€æŸ¥å¥åº·çŠ¶æ€
curl http://localhost:8000/health
curl http://localhost:8001/health
curl http://localhost:8002/health

# æµ‹è¯• STTï¼ˆè¯­éŸ³è¯†åˆ«ï¼‰
curl -X POST http://localhost:8001/v1/audio/transcriptions \
  -F "file=@test_audio.wav" \
  -F "model=qwen3-asr"

# æµ‹è¯• TTSï¼ˆè¯­éŸ³åˆæˆï¼‰
curl -X POST http://localhost:8002/v1/audio/speech \
  -H "Content-Type: application/json" \
  -d '{"input":"ä½ å¥½ä¸–ç•Œ","voice":"default","model":"qwen3-tts"}' \
  --output output.wav
```

---

## ğŸ”§ é…ç½®è¯´æ˜

### ç¯å¢ƒå˜é‡

#### Gateway æœåŠ¡

| å˜é‡ | é»˜è®¤å€¼ | è¯´æ˜ |
|------|--------|------|
| `GATEWAY_HOST` | `0.0.0.0` | ç›‘å¬åœ°å€ |
| `GATEWAY_PORT` | `8000` | ç›‘å¬ç«¯å£ |
| `STT_SERVICE_URL` | `http://stt-service:8001` | STT æœåŠ¡åœ°å€ |
| `TTS_SERVICE_URL` | `http://tts-service:8002` | TTS æœåŠ¡åœ°å€ |
| `LOG_LEVEL` | `INFO` | æ—¥å¿—çº§åˆ« |

#### STT æœåŠ¡

| å˜é‡ | é»˜è®¤å€¼ | è¯´æ˜ |
|------|--------|------|
| `SERVICE_HOST` | `0.0.0.0` | ç›‘å¬åœ°å€ |
| `SERVICE_PORT` | `8001` | ç›‘å¬ç«¯å£ |
| `QWEN_ASR_MODEL` | `Qwen/Qwen3-ASR-0.6B` | æ¨¡å‹åç§° |
| `QWEN_ASR_DEVICE` | `cuda:0` | ä½¿ç”¨çš„ GPU |
| `HF_ENDPOINT` | `https://hf-mirror.com` | Hugging Face é•œåƒ |

#### TTS æœåŠ¡

| å˜é‡ | é»˜è®¤å€¼ | è¯´æ˜ |
|------|--------|------|
| `SERVICE_HOST` | `0.0.0.0` | ç›‘å¬åœ°å€ |
| `SERVICE_PORT` | `8002` | ç›‘å¬ç«¯å£ |
| `QWEN_TTS_MODEL` | `Qwen/Qwen3-TTS-12Hz-0.6B-CustomVoice` | æ¨¡å‹åç§° |
| `QWEN_TTS_DEVICE` | `cuda:0` | ä½¿ç”¨çš„ GPU |
| `HF_ENDPOINT` | `https://hf-mirror.com` | Hugging Face é•œåƒ |

### æ¨¡å‹ä¸‹è½½

**æ¨¡å‹ä¼šåœ¨é¦–æ¬¡å¯åŠ¨æ—¶è‡ªåŠ¨ä¸‹è½½**ï¼Œç¼“å­˜åœ¨å®¹å™¨å†…çš„ `/root/.cache/huggingface` ç›®å½•ã€‚

å¦‚æœæƒ³æŒä¹…åŒ–æ¨¡å‹ç¼“å­˜ï¼Œå¯ä»¥æ·»åŠ  volume æŒ‚è½½ï¼š

```yaml
volumes:
  - ./models:/models
  - ./cache:/root/.cache  # æŒä¹…åŒ–æ¨¡å‹ç¼“å­˜
```

---

## ğŸ› æ•…éšœæ’æŸ¥

### 1. é•œåƒæ‹‰å–å¤±è´¥

**é—®é¢˜**ï¼š`unauthorized` æˆ– `connection timeout`

**è§£å†³**ï¼š
- å›½é™…ç”¨æˆ·ï¼šæ£€æŸ¥ç½‘ç»œè¿æ¥ï¼Œæˆ–ä½¿ç”¨ä»£ç†
- å›½å†…ç”¨æˆ·ï¼šä½¿ç”¨ `ghcr.1ms.run` é•œåƒæº

### 2. GPU ä¸å¯ç”¨

**é—®é¢˜**ï¼šå®¹å™¨å†…æ— æ³•ä½¿ç”¨ GPU

**è§£å†³**ï¼š
```bash
# æ£€æŸ¥ NVIDIA é©±åŠ¨
nvidia-smi

# æ£€æŸ¥ Docker GPU æ”¯æŒ
docker run --rm --gpus all nvidia/cuda:12.1.0-base-ubuntu22.04 nvidia-smi

# é‡æ–°å®‰è£… NVIDIA Container Toolkit
sudo apt-get install -y nvidia-container-toolkit
sudo systemctl restart docker
```

### 3. æ¨¡å‹ä¸‹è½½æ…¢

**é—®é¢˜**ï¼šé¦–æ¬¡å¯åŠ¨æ—¶æ¨¡å‹ä¸‹è½½å¾ˆæ…¢

**è§£å†³**ï¼š
- ä½¿ç”¨ Hugging Face é•œåƒï¼š`HF_ENDPOINT=https://hf-mirror.com`
- æˆ–æ‰‹åŠ¨ä¸‹è½½æ¨¡å‹åæŒ‚è½½åˆ°å®¹å™¨

### 4. æ˜¾å­˜ä¸è¶³

**é—®é¢˜**ï¼š`CUDA out of memory`

**è§£å†³**ï¼š
- ç¡®ä¿ GPU æœ‰è‡³å°‘ 4GB æ˜¾å­˜
- å…³é—­å…¶ä»–å ç”¨ GPU çš„ç¨‹åº
- é™ä½ batch sizeï¼š`QWEN_ASR_MAX_BATCH_SIZE=4`

---

## ğŸ“Š æ€§èƒ½ä¼˜åŒ–

### GPU æ˜¾å­˜ä¼˜åŒ–

**GTX 1050 Ti (4GB)** - å•æœåŠ¡æ¨¡å¼ï¼š
```yaml
# åªè¿è¡Œ STT æˆ– TTSï¼Œä¸è¦åŒæ—¶è¿è¡Œ
docker-compose up -d gateway stt-service
# æˆ–
docker-compose up -d gateway tts-service
```

**RTX 2080 Ti (22GB)** - å…¨æœåŠ¡æ¨¡å¼ï¼š
```yaml
# å¯ä»¥åŒæ—¶è¿è¡Œæ‰€æœ‰æœåŠ¡
docker-compose up -d
```

### ç½‘ç»œä¼˜åŒ–

**å›½å†…ç”¨æˆ·**ï¼š
- ä½¿ç”¨ `ghcr.1ms.run` é•œåƒæº
- ä½¿ç”¨ `HF_ENDPOINT=https://hf-mirror.com`
- é…ç½® Docker é•œåƒåŠ é€Ÿå™¨

---

## ğŸ“š ç›¸å…³é“¾æ¥

- **GitHub ä»“åº“**: https://github.com/DDKTopLabs/OpenTalker
- **é•œåƒä»“åº“**: 
  - Gateway: https://github.com/orgs/DDKTopLabs/packages/container/package/opentalker-gateway
  - STT: https://github.com/orgs/DDKTopLabs/packages/container/package/opentalker-stt
  - TTS: https://github.com/orgs/DDKTopLabs/packages/container/package/opentalker-tts
- **å›½å†…é•œåƒæº**: https://1ms.run

---

## ğŸ“„ è®¸å¯è¯

æœ¬é¡¹ç›®éµå¾ª MIT è®¸å¯è¯ã€‚

---

**æœ€åæ›´æ–°**: 2026-02-04  
**ç‰ˆæœ¬**: v0.3.0  
**çŠ¶æ€**: âœ… æ‰€æœ‰é•œåƒå·²å…¬å¼€å‘å¸ƒ
